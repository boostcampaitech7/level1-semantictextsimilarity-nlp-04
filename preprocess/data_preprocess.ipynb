{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# 모든 경고 메시지 무시\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨 분포 확인용\n",
    "def print_label_count(df):\n",
    "    print(len(df))\n",
    "    df[\"label_int\"] = pd.cut(\n",
    "        df[\"label\"],\n",
    "        bins=[x for x in range(6)],\n",
    "        labels=[x for x in range(5)],\n",
    "        right=False,\n",
    "    )\n",
    "    print(df.groupby(\"label_int\")[\"id\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hanspell import passportKey, spell_checker\n",
    "# passportKey 설정\n",
    "passportKey.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "맞춤법 틀리면 왜 안돼? 쓰고 싶은 대로 쓰면 되지 돼지야 \n"
     ]
    }
   ],
   "source": [
    "sent = \"맞춤법 틀리면 외 않되? 쓰고싶은대로쓰면돼지 되지야 \"\n",
    "spelled_sent = spell_checker.check(sent)\n",
    "\n",
    "hanspell_sent = spelled_sent.checked\n",
    "print(hanspell_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pykospacing\n",
    "\n",
    "\n",
    "# 띄어쓰기 교정\n",
    "def spacing_text(df):\n",
    "    spacing = pykospacing.Spacing()\n",
    "    df[\"sentence_1\"] = df[\"sentence_1\"].map(spacing)\n",
    "    df[\"sentence_2\"] = df[\"sentence_2\"].map(spacing)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Speicial 토큰 처리\n",
    "def replace_person_token(df):\n",
    "    df[\"sentence_1\"] = df[\"sentence_1\"].str.replace(\"<PERSON>\", \"궯궯궯\")\n",
    "    df[\"sentence_2\"] = df[\"sentence_2\"].str.replace(\"<PERSON>\", \"궯궯궯\")\n",
    "    return df \n",
    "\n",
    "\n",
    "def recover_person_token(df):\n",
    "    df[\"sentence_1\"] = df[\"sentence_1\"].str.replace(\"궯궯궯\", \"<PERSON>\")\n",
    "    df[\"sentence_2\"] = df[\"sentence_2\"].str.replace(\"궯궯궯\", \"<PERSON>\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swap data\n",
    "def agument_with_swap(df):\n",
    "    df_swaped = df.rename(\n",
    "        columns={\"sentence_1\": \"sentence_2\", \"sentence_2\": \"sentence_1\"}\n",
    "    )\n",
    "    return pd.concat([df, df_swaped])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 증강\n",
    "import random\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "wordnet = {}\n",
    "with open(\"./wordnet.pickle\", \"rb\") as f:\n",
    "    wordnet = pickle.load(f)\n",
    "\n",
    "\n",
    "# 한글만 남기고 나머지는 삭제\n",
    "def get_only_hangul(line):\n",
    "    parseText = re.compile(\"/ ^[ㄱ-ㅎㅏ-ㅣ가-힣]*$/\").sub(\"\", line)\n",
    "\n",
    "    return parseText\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# Synonym replacement\n",
    "# Replace n words in the sentence with synonyms from wordnet\n",
    "########################################################################\n",
    "def synonym_replacement(words, n):\n",
    "    new_words = words.copy()\n",
    "    random_word_list = list(set([word for word in words]))\n",
    "    random.shuffle(random_word_list)\n",
    "    num_replaced = 0\n",
    "    for random_word in random_word_list:\n",
    "        synonyms = get_synonyms(random_word)\n",
    "        if len(synonyms) >= 1:\n",
    "            synonym = random.choice(list(synonyms))\n",
    "            new_words = [synonym if word == random_word else word for word in new_words]\n",
    "            num_replaced += 1\n",
    "        if num_replaced >= n:\n",
    "            break\n",
    "\n",
    "    if len(new_words) != 0:\n",
    "        sentence = \" \".join(new_words)\n",
    "        new_words = sentence.split(\" \")\n",
    "\n",
    "    else:\n",
    "        new_words = \"\"\n",
    "\n",
    "    return new_words\n",
    "\n",
    "\n",
    "def get_synonyms(word):\n",
    "    synomyms = []\n",
    "\n",
    "    try:\n",
    "        for syn in wordnet[word]:\n",
    "            for s in syn:\n",
    "                synomyms.append(s)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return synomyms\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# Random deletion\n",
    "# Randomly delete words from the sentence with probability p\n",
    "########################################################################\n",
    "def random_deletion(words, p):\n",
    "    if len(words) == 1:\n",
    "        return words\n",
    "\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        r = random.uniform(0, 1)\n",
    "        if r > p:\n",
    "            new_words.append(word)\n",
    "\n",
    "    if len(new_words) == 0:\n",
    "        rand_int = random.randint(0, len(words) - 1)\n",
    "        return [words[rand_int]]\n",
    "\n",
    "    return new_words\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# Random swap\n",
    "# Randomly swap two words in the sentence n times\n",
    "########################################################################\n",
    "def random_swap(words, n):\n",
    "    new_words = words.copy()\n",
    "    for _ in range(n):\n",
    "        new_words = swap_word(new_words)\n",
    "\n",
    "    return new_words\n",
    "\n",
    "\n",
    "def swap_word(new_words):\n",
    "    random_idx_1 = random.randint(0, len(new_words) - 1)\n",
    "    random_idx_2 = random_idx_1\n",
    "    counter = 0\n",
    "\n",
    "    while random_idx_2 == random_idx_1:\n",
    "        random_idx_2 = random.randint(0, len(new_words) - 1)\n",
    "        counter += 1\n",
    "        if counter > 3:\n",
    "            return new_words\n",
    "\n",
    "    new_words[random_idx_1], new_words[random_idx_2] = (\n",
    "        new_words[random_idx_2],\n",
    "        new_words[random_idx_1],\n",
    "    )\n",
    "    return new_words\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# Random insertion\n",
    "# Randomly insert n words into the sentence\n",
    "########################################################################\n",
    "def random_insertion(words, n):\n",
    "    new_words = words.copy()\n",
    "    for _ in range(n):\n",
    "        add_word(new_words)\n",
    "\n",
    "    return new_words\n",
    "\n",
    "\n",
    "def add_word(new_words):\n",
    "    synonyms = []\n",
    "    counter = 0\n",
    "    while len(synonyms) < 1:\n",
    "        if len(new_words) >= 1:\n",
    "            random_word = new_words[random.randint(0, len(new_words) - 1)]\n",
    "            synonyms = get_synonyms(random_word)\n",
    "            counter += 1\n",
    "        else:\n",
    "            random_word = \"\"\n",
    "\n",
    "        if counter >= 10:\n",
    "            return\n",
    "\n",
    "    random_synonym = synonyms[0]\n",
    "    random_idx = random.randint(0, len(new_words) - 1)\n",
    "    new_words.insert(random_idx, random_synonym)\n",
    "\n",
    "\n",
    "def EDA(sentence, alpha_sr=0.1, alpha_ri=0.1, alpha_rs=0.1, num_aug=9):\n",
    "    sentence = get_only_hangul(sentence)\n",
    "    words = sentence.split(\" \")\n",
    "    words = [word for word in words if word != \"\"]\n",
    "    num_words = len(words)\n",
    "\n",
    "    augmented_sentences = []\n",
    "    num_new_per_technique = int(num_aug / 3) + 1  # 3가지 증강 기법에 맞춰서 수정\n",
    "\n",
    "    n_sr = max(1, int(alpha_sr * num_words))\n",
    "    n_ri = max(1, int(alpha_ri * num_words))\n",
    "    n_rs = max(1, int(alpha_rs * num_words))\n",
    "\n",
    "    # sr: Synonym replacement\n",
    "    for _ in range(num_new_per_technique):\n",
    "        a_words = synonym_replacement(words, n_sr)\n",
    "        augmented_sentences.append(\" \".join(a_words))\n",
    "\n",
    "    # ri: Random insertion\n",
    "    for _ in range(num_new_per_technique):\n",
    "        a_words = random_insertion(words, n_ri)\n",
    "        augmented_sentences.append(\" \".join(a_words))\n",
    "\n",
    "    # rs: Random swap\n",
    "    for _ in range(num_new_per_technique):\n",
    "        a_words = random_swap(words, n_rs)\n",
    "        augmented_sentences.append(\" \".join(a_words))\n",
    "\n",
    "    # Hangul cleanup and shuffle\n",
    "    augmented_sentences = [\n",
    "        get_only_hangul(sentence) for sentence in augmented_sentences\n",
    "    ]\n",
    "    random.shuffle(augmented_sentences)\n",
    "\n",
    "    # Limit the number of augmentations to num_aug\n",
    "    if num_aug >= 1:\n",
    "        augmented_sentences = augmented_sentences[:num_aug]\n",
    "    else:\n",
    "        keep_prob = num_aug / len(augmented_sentences)\n",
    "        augmented_sentences = [\n",
    "            s for s in augmented_sentences if random.uniform(0, 1) < keep_prob\n",
    "        ]\n",
    "\n",
    "    # Original sentence 포함\n",
    "    augmented_sentences.append(sentence)\n",
    "\n",
    "    return augmented_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA 적용 함수\n",
    "def apply_eda(df, alpha_sr=0.1, alpha_ri=0.1, alpha_rs=0.1, num_aug=2):\n",
    "    def conditional_EDA(row, column_name):\n",
    "        if row[\"label\"] >= 1:  \n",
    "            return EDA(\n",
    "                row[column_name], alpha_sr, alpha_ri, alpha_rs, num_aug)\n",
    "        else:\n",
    "            return [row[column_name]]\n",
    "\n",
    "    df[\"sentence_1\"] = df.apply(lambda row: conditional_EDA(row, \"sentence_1\"), axis=1)\n",
    "    df = df.explode(\"sentence_1\").reset_index(drop=True)\n",
    "\n",
    "    df[\"sentence_2\"] = df.apply(lambda row: conditional_EDA(row, \"sentence_2\"), axis=1)\n",
    "    df = df.explode(\"sentence_2\").reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make(df, df_name):\n",
    "    df = spacing_text(df)\n",
    "    df = replace_person_token(df)\n",
    "    df = apply_eda(df)\n",
    "    df = recover_person_token(df)\n",
    "    df = agument_with_swap(df)\n",
    "    df = df.drop_duplicates()\n",
    "    df.to_csv(f\"./{df_name}.csv\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               object\n",
       "source           object\n",
       "sentence_1       object\n",
       "sentence_2       object\n",
       "label           float64\n",
       "binary-label    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트용\n",
    "train_02 = pd.read_csv(\"../data/processed/train_02.csv\", encoding=\"UTF-8\")\n",
    "train_02.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/raw/train.csv\", encoding=\"UTF-8\")\n",
    "dev = pd.read_csv(\"../data/raw/dev.csv\", encoding=\"UTF-8\")\n",
    "\n",
    "train = make(train, \"train_v2\")\n",
    "dev = make(dev, \"dev_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68286\n",
      "label_int\n",
      "0     7422\n",
      "1    15066\n",
      "2    12362\n",
      "3    18678\n",
      "4    13906\n",
      "Name: id, dtype: int64\n",
      "5094\n",
      "label_int\n",
      "0     176\n",
      "1    1122\n",
      "2    1222\n",
      "3    1212\n",
      "4    1163\n",
      "Name: id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print_label_count(train)\n",
    "print_label_count(dev)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ame",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
